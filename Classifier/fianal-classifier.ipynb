{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "\n",
      "Validation Set Performance:\n",
      "Accuracy: 0.882\n",
      "F1 Score: 0.900\n",
      "ROC AUC: 0.931\n",
      "Precision: 0.818\n",
      "Recall: 1.000\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.952\n",
      "F1 Score: 0.957\n",
      "ROC AUC: 0.982\n",
      "Precision: 0.917\n",
      "Recall: 1.000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  1]\n",
      " [ 0 11]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the entire dataset\n",
    "data = pd.read_excel('data.xlsx')[:103]\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Split the data\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Classifiers with class_weight adjustments\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "xgb = XGBClassifier(random_state=42, scale_pos_weight=1)\n",
    "lr = LogisticRegression(random_state=42, max_iter=5000, tol=1e-4, class_weight='balanced')\n",
    "sgd = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, class_weight='balanced')\n",
    "svm = SVC(random_state=42, probability=True, class_weight='balanced')\n",
    "\n",
    "# Pipeline without SMOTE\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('classifier', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf),\n",
    "            ('xgb', xgb),\n",
    "            ('lr', lr),\n",
    "            ('sgd', sgd),\n",
    "            ('svm', svm)\n",
    "        ],\n",
    "        voting='soft'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Adjusted hyperparameter distributions\n",
    "param_dist = {\n",
    "    'classifier__rf__n_estimators': randint(100, 500),\n",
    "    'classifier__rf__max_depth': randint(5, 20),\n",
    "    'classifier__rf__min_samples_split': randint(2, 10),\n",
    "    'classifier__rf__min_samples_leaf': randint(1, 5),\n",
    "    'classifier__xgb__n_estimators': randint(100, 500),\n",
    "    'classifier__xgb__max_depth': randint(3, 10),\n",
    "    'classifier__xgb__learning_rate': uniform(0.01, 0.3),\n",
    "    'classifier__xgb__subsample': uniform(0.7, 0.3),\n",
    "    'classifier__xgb__colsample_bytree': uniform(0.7, 0.3),\n",
    "    'classifier__xgb__scale_pos_weight': [1, 2, 5, 10],\n",
    "    'classifier__lr__C': uniform(0.1, 10),\n",
    "    'classifier__lr__penalty': ['l2'],\n",
    "    'classifier__lr__solver': ['saga'],\n",
    "    'classifier__sgd__alpha': uniform(1e-5, 1e-1),\n",
    "    'classifier__sgd__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'classifier__sgd__loss': ['log_loss', 'modified_huber'],\n",
    "    'classifier__svm__C': uniform(0.1, 10),\n",
    "    'classifier__svm__kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomizedSearchCV with F1-score optimization\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=param_dist, n_iter=400,\n",
    "    cv=cv, scoring='f1', n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"\\nValidation Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_val_pred_proba):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_val_pred):.3f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_pred_proba):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred):.3f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters found by RandomizedSearchCV:\n",
      "{'classifier__lr__C': 3.3337156211552075, 'classifier__lr__penalty': 'l2', 'classifier__lr__solver': 'saga', 'classifier__rf__max_depth': 15, 'classifier__rf__min_samples_leaf': 2, 'classifier__rf__min_samples_split': 2, 'classifier__rf__n_estimators': 295, 'classifier__sgd__alpha': 0.04425099364806696, 'classifier__sgd__loss': 'modified_huber', 'classifier__sgd__penalty': 'l1', 'classifier__svm__C': 6.7960261613396185, 'classifier__svm__kernel': 'sigmoid', 'classifier__xgb__colsample_bytree': 0.8920504671484497, 'classifier__xgb__learning_rate': 0.09134423095005544, 'classifier__xgb__max_depth': 4, 'classifier__xgb__n_estimators': 166, 'classifier__xgb__scale_pos_weight': 2, 'classifier__xgb__subsample': 0.7692487567462036}\n"
     ]
    }
   ],
   "source": [
    "best_model = search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Hyperparameters found by RandomizedSearchCV:\")\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Performance:\n",
      "Accuracy: 0.882\n",
      "F1 Score: 0.900\n",
      "ROC AUC: 0.931\n",
      "Precision: 0.818\n",
      "Recall: 1.000\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.952\n",
      "F1 Score: 0.957\n",
      "ROC AUC: 0.973\n",
      "Precision: 0.917\n",
      "Recall: 1.000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  1]\n",
      " [ 0 11]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_excel('data.xlsx')[:103]\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=295, max_depth=15, min_samples_leaf=2, min_samples_split=2, random_state=42, class_weight='balanced')\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=700, \n",
    "    max_depth=4,\n",
    "    learning_rate=0.09134423095005544,\n",
    "    subsample=0.7692487567462036,\n",
    "    colsample_bytree=0.8920504671484497,\n",
    "    scale_pos_weight=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    C=3.3337156211552075, penalty='l2', solver='saga', max_iter=10000, random_state=42, class_weight='balanced'\n",
    ")\n",
    "\n",
    "sgd = SGDClassifier(\n",
    "    alpha=0.04425099364806696, loss='modified_huber', penalty='l1', max_iter=5000, random_state=42, class_weight='balanced'\n",
    ")\n",
    "\n",
    "svm = SVC(\n",
    "    C=6.7960261613396185, kernel='sigmoid', probability=True, random_state=42, class_weight='balanced'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('classifier', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf),\n",
    "            ('xgb', xgb),\n",
    "            ('lr', lr),\n",
    "            ('sgd', sgd),\n",
    "            ('svm', svm)\n",
    "        ],\n",
    "        voting='soft'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "y_val_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print(\"\\nValidation Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_val_pred_proba):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_val_pred):.3f}\")\n",
    "\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "y_test_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_pred_proba):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred):.3f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on the whole dataset have been saved to 'final_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('data.xlsx')\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X = data.drop('Class', axis=1)\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'user_id': data['user_id'],  \n",
    "    'Predicted_Class': y_pred\n",
    "})\n",
    "\n",
    "results_df.to_csv('final_predictions.csv', index=False)\n",
    "print(\"\\nPredictions on the whole dataset have been saved to 'final_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
